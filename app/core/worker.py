import time
import sys
import os
import asyncio
import logging
from aiogram import Bot
from dotenv import load_dotenv

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø—É—Ç–µ–π
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from models.database import Session
from models.db_models import Job, User
from services.downloader import VideoDownloader
from core.analyzer import AIAnalyzer
from core.renderer import VideoRenderer

# –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–æ–∫–µ–Ω –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤–∏–¥–µ–æ
load_dotenv()
API_TOKEN = os.getenv("BOT_TOKEN")
bot = Bot(token=API_TOKEN)

async def process_jobs():
    dl = VideoDownloader()
    analyzer = AIAnalyzer(model_size="base")
    renderer = VideoRenderer()
    
    print("--- [üöÄ] –ö–æ–Ω–≤–µ–π–µ—Ä NEUROCLIPPER —Å –∞–≤—Ç–æ-–æ—Ç–ø—Ä–∞–≤–∫–æ–π –∑–∞–ø—É—â–µ–Ω...")
    
    while True:
        session = Session()
        job = session.query(Job).filter(Job.status == 'pending').first()
        
        if job:
            print(f"--- [‚öôÔ∏è] –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–¥–∞—á–∏ #{job.id} –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {job.user_id}")
            job.status = 'processing'
            session.commit()
            
            # 1. –ó–∞–≥—Ä—É–∑–∫–∞
            file_path = dl.download(job.input_url, f"source_{job.id}")
            
            if file_path:
                # 2. –ê–Ω–∞–ª–∏–∑
                segments = analyzer.transcribe(file_path)
                highlights = analyzer.find_highlights(segments)
                
                if highlights:
                    # –ë–µ—Ä–µ–º —Å–∞–º—ã–π —Å–æ—á–Ω—ã–π —Ö–∞–π–ª–∞–π—Ç (–ø–µ—Ä–≤—ã–π)
                    h = highlights[0]
                    # 3. –†–µ–Ω–¥–µ—Ä–∏–Ω–≥
                    try:
                        clip_path = renderer.create_short(
                            file_path, h['start'], h['end'], h['text'], f"result_{job.id}"
                        )
                        
                        # 4. –û–¢–ü–†–ê–í–ö–ê –í –¢–ï–õ–ï–ì–†–ê–ú
                        user = session.query(User).filter(User.id == job.user_id).first()
                        if user:
                            print(f"--- [üì§] –û—Ç–ø—Ä–∞–≤–∫–∞ –≤–∏–¥–µ–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é {user.tg_id}...")
                            from aiogram.types import FSInputFile
                            video_file = FSInputFile(clip_path)
                            await bot.send_video(
                                user.tg_id, 
                                video_file, 
                                caption=f"üé¨ –¢–≤–æ–π –∫–ª–∏–ø –≥–æ—Ç–æ–≤!\n\n–¢–µ–∫—Å—Ç: {h['text']}"
                            )
                        
                        job.status = 'done'
                    except Exception as e:
                        print(f"--- [‚ùå] –û—à–∏–±–∫–∞ —Ä–µ–Ω–¥–µ—Ä–∏–Ω–≥–∞/–æ—Ç–ø—Ä–∞–≤–∫–∏: {e}")
                        job.status = 'error'
                else:
                    print("--- [ü§∑] –•–∞–π–ª–∞–π—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.")
                    job.status = 'no_highlights'
            else:
                job.status = 'error'
            
            session.commit()
        
        session.close()
        await asyncio.sleep(5)

if __name__ == "__main__":
    asyncio.run(process_jobs())